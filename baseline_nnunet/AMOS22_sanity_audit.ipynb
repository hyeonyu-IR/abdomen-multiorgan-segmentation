{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1545bb",
   "metadata": {},
   "source": [
    "# AMOS22 Sanity Audit (Pairing, Shapes, Labels, Basic Header Checks)\n",
    "\n",
    "This notebook performs **dataset integrity checks** before training:\n",
    "\n",
    "- confirms image/label pairing (train + validation)\n",
    "- checks image and label shapes match\n",
    "- checks label value range (expects integers 0..15 based on your `dataset.json`)\n",
    "- checks basic header/affine similarity (not strict equality, but flags large differences)\n",
    "- writes CSV summaries you can keep with the run record\n",
    "\n",
    "> This is designed to be **fast enough** to run locally and produce actionable QC outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6130472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT: C:\\Users\\hyeon\\Documents\\miniconda_medimg_env\\data\\amos22\n",
      "OUT_DIR  : C:\\Users\\hyeon\\Documents\\miniconda_medimg_env\\abdomen-multiorgan-segmentation\\baseline_nnunet\\outputs_audit\n",
      "Time     : 2026-02-04T09:53:21\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — Setup\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_ROOT = Path(r\"C:/Users/hyeon/Documents/miniconda_medimg_env/data/amos22\")\n",
    "OUT_DIR = Path(\"outputs_audit\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA_ROOT:\", DATA_ROOT.resolve())\n",
    "print(\"OUT_DIR  :\", OUT_DIR.resolve())\n",
    "print(\"Time     :\", datetime.now().isoformat(timespec=\"seconds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90115c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in dataset.json: 16\n",
      "Expected label id range: 0 to 15\n",
      "Label map (id -> name):\n",
      "  0: background\n",
      "  1: spleen\n",
      "  2: right kidney\n",
      "  3: left kidney\n",
      "  4: gall bladder\n",
      "  5: esophagus\n",
      "  6: liver\n",
      "  7: stomach\n",
      "  8: arota\n",
      "  9: postcava\n",
      "  10: pancreas\n",
      "  11: right adrenal gland\n",
      "  12: left adrenal gland\n",
      "  13: duodenum\n",
      "  14: bladder\n",
      "  15: prostate/uterus\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — Load expected labels from dataset.json\n",
    "ds = json.loads((DATA_ROOT / \"dataset.json\").read_text(encoding=\"utf-8\"))\n",
    "labels = ds.get(\"labels\", {})\n",
    "# labels is typically {\"0\":\"background\", \"1\":\"spleen\", ...}\n",
    "label_ids = sorted([int(k) for k in labels.keys()])\n",
    "expected_min = min(label_ids) if label_ids else 0\n",
    "expected_max = max(label_ids) if label_ids else 0\n",
    "\n",
    "print(\"Labels in dataset.json:\", len(label_ids))\n",
    "print(\"Expected label id range:\", expected_min, \"to\", expected_max)\n",
    "print(\"Label map (id -> name):\")\n",
    "for k in sorted(labels.keys(), key=lambda x: int(x)):\n",
    "    print(f\"  {k}: {labels[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bc9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Utility functions\n",
    "def list_niigz(folder: Path):\n",
    "    if not folder.exists():\n",
    "        return []\n",
    "    return sorted([p for p in folder.iterdir() if p.is_file() and p.name.endswith(\".nii.gz\")])\n",
    "\n",
    "def stem_niigz(p: Path) -> str:\n",
    "    return p.name[:-7] if p.name.endswith(\".nii.gz\") else p.stem\n",
    "\n",
    "def affine_diff_mm(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    # crude measure: max absolute diff in translation component\n",
    "    return float(np.max(np.abs(a[:3, 3] - b[:3, 3])))\n",
    "\n",
    "def spacing_from_affine(aff: np.ndarray) -> tuple:\n",
    "    # voxel spacing is norm of column vectors\n",
    "    return tuple(np.linalg.norm(aff[:3, :3], axis=0).tolist())\n",
    "\n",
    "def audit_split(images_dir: Path, labels_dir: Path | None, split_name: str):\n",
    "    imgs = list_niigz(images_dir)\n",
    "    labs = {stem_niigz(p): p for p in list_niigz(labels_dir)} if labels_dir else {}\n",
    "\n",
    "    rows = []\n",
    "    missing = []\n",
    "    for img_path in imgs:\n",
    "        sid = stem_niigz(img_path)\n",
    "        lbl_path = labs.get(sid, None) if labels_dir else None\n",
    "\n",
    "        if labels_dir and lbl_path is None:\n",
    "            missing.append(sid)\n",
    "            continue\n",
    "\n",
    "        img = nib.load(str(img_path))\n",
    "        img_shape = tuple(img.shape)\n",
    "        img_spacing = spacing_from_affine(img.affine)\n",
    "\n",
    "        if lbl_path is not None:\n",
    "            lbl = nib.load(str(lbl_path))\n",
    "            lbl_shape = tuple(lbl.shape)\n",
    "            lbl_spacing = spacing_from_affine(lbl.affine)\n",
    "            shape_match = (img_shape == lbl_shape)\n",
    "\n",
    "            # Read label data (as int) and compute min/max/unique count\n",
    "            arr = np.asanyarray(lbl.dataobj)\n",
    "            # labels should be integer-like; cast safely\n",
    "            arr_int = arr.astype(np.int32, copy=False)\n",
    "            lbl_min = int(arr_int.min())\n",
    "            lbl_max = int(arr_int.max())\n",
    "            # avoid huge unique materialization; sample if needed\n",
    "            uniq = np.unique(arr_int) if arr_int.size <= 50_000_000 else np.unique(arr_int.ravel()[::50])\n",
    "            uniq_count = int(len(uniq))\n",
    "            unexpected = False\n",
    "            if lbl_min < expected_min or lbl_max > expected_max:\n",
    "                unexpected = True\n",
    "\n",
    "            a_diff = affine_diff_mm(img.affine, lbl.affine)\n",
    "\n",
    "            rows.append({\n",
    "                \"split\": split_name,\n",
    "                \"id\": sid,\n",
    "                \"image\": img_path.name,\n",
    "                \"label\": lbl_path.name,\n",
    "                \"img_shape\": str(img_shape),\n",
    "                \"lbl_shape\": str(lbl_shape),\n",
    "                \"shape_match\": shape_match,\n",
    "                \"img_spacing\": str(tuple(round(x, 4) for x in img_spacing)),\n",
    "                \"lbl_spacing\": str(tuple(round(x, 4) for x in lbl_spacing)),\n",
    "                \"affine_translation_diff_mm\": round(a_diff, 4),\n",
    "                \"label_min\": lbl_min,\n",
    "                \"label_max\": lbl_max,\n",
    "                \"unique_label_count\": uniq_count,\n",
    "                \"has_unexpected_label_range\": unexpected,\n",
    "            })\n",
    "        else:\n",
    "            rows.append({\n",
    "                \"split\": split_name,\n",
    "                \"id\": sid,\n",
    "                \"image\": img_path.name,\n",
    "                \"label\": \"\",\n",
    "                \"img_shape\": str(img_shape),\n",
    "                \"lbl_shape\": \"\",\n",
    "                \"shape_match\": \"\",\n",
    "                \"img_spacing\": str(tuple(round(x, 4) for x in img_spacing)),\n",
    "                \"lbl_spacing\": \"\",\n",
    "                \"affine_translation_diff_mm\": \"\",\n",
    "                \"label_min\": \"\",\n",
    "                \"label_max\": \"\",\n",
    "                \"unique_label_count\": \"\",\n",
    "                \"has_unexpected_label_range\": \"\",\n",
    "            })\n",
    "\n",
    "    return rows, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb99573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 240\n",
      "Train labels: 240\n",
      "Missing train labels: 0\n",
      "Val images: 120\n",
      "Val labels: 120\n",
      "Missing val labels: 0\n",
      "Test images: 240\n",
      "Wrote: C:\\Users\\hyeon\\Documents\\miniconda_medimg_env\\abdomen-multiorgan-segmentation\\baseline_nnunet\\outputs_audit\\amos22_audit_table.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — Run audits for Train + Validation + Test\n",
    "train_rows, train_missing = audit_split(DATA_ROOT/\"imagesTr\", DATA_ROOT/\"labelsTr\", \"train\")\n",
    "val_rows, val_missing = audit_split(DATA_ROOT/\"imagesVa\", DATA_ROOT/\"labelsVa\", \"val\")\n",
    "test_rows, _ = audit_split(DATA_ROOT/\"imagesTs\", None, \"test_no_labels\")\n",
    "\n",
    "df = pd.DataFrame(train_rows + val_rows + test_rows)\n",
    "\n",
    "print(\"Train images:\", len(list_niigz(DATA_ROOT/'imagesTr')))\n",
    "print(\"Train labels:\", len(list_niigz(DATA_ROOT/'labelsTr')))\n",
    "print(\"Missing train labels:\", len(train_missing))\n",
    "\n",
    "print(\"Val images:\", len(list_niigz(DATA_ROOT/'imagesVa')))\n",
    "print(\"Val labels:\", len(list_niigz(DATA_ROOT/'labelsVa')))\n",
    "print(\"Missing val labels:\", len(val_missing))\n",
    "\n",
    "print(\"Test images:\", len(list_niigz(DATA_ROOT/'imagesTs')))\n",
    "\n",
    "# Save full audit table\n",
    "csv_path = OUT_DIR / \"amos22_audit_table.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"Wrote:\", csv_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f41a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape mismatches: 0\n",
      "\n",
      "Unexpected label range cases: 0\n",
      "\n",
      "Affine translation diff > 1mm: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 — Summaries: problems to fix first\n",
    "# 1) Pairing issues\n",
    "if train_missing:\n",
    "    print(\"⚠️ Missing TRAIN labels for (showing up to 20):\", train_missing[:20])\n",
    "if val_missing:\n",
    "    print(\"⚠️ Missing VAL labels for (showing up to 20):\", val_missing[:20])\n",
    "\n",
    "# 2) Shape mismatches\n",
    "bad_shape = df[(df[\"split\"].isin([\"train\",\"val\"])) & (df[\"shape_match\"] == False)]\n",
    "print(\"\\nShape mismatches:\", len(bad_shape))\n",
    "if len(bad_shape):\n",
    "    display(bad_shape.head(20))\n",
    "\n",
    "# 3) Unexpected label ranges\n",
    "bad_labels = df[(df[\"split\"].isin([\"train\",\"val\"])) & (df[\"has_unexpected_label_range\"] == True)]\n",
    "print(\"\\nUnexpected label range cases:\", len(bad_labels))\n",
    "if len(bad_labels):\n",
    "    display(bad_labels.head(20))\n",
    "\n",
    "# 4) Large affine translation differences (heuristic; > 1mm)\n",
    "sub = df[df[\"split\"].isin([\"train\", \"val\"])].copy()\n",
    "sub[\"affine_translation_diff_mm\"] = pd.to_numeric(sub[\"affine_translation_diff_mm\"], errors=\"coerce\")\n",
    "aff_bad = sub[sub[\"affine_translation_diff_mm\"] > 1.0]\n",
    "\n",
    "print(\"\\nAffine translation diff > 1mm:\", len(aff_bad))\n",
    "if len(aff_bad):\n",
    "    display(aff_bad.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e56e7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top image spacings (train):\n",
      "spacing_r\n",
      "(0.78, 0.78, 5.0)    42\n",
      "(0.65, 0.65, 5.0)    14\n",
      "(1.19, 1.19, 3.0)    10\n",
      "(0.82, 1.1, 0.82)     9\n",
      "(0.61, 0.61, 5.0)     8\n",
      "(0.54, 0.54, 5.0)     7\n",
      "(0.69, 0.69, 2.0)     5\n",
      "(1.19, 3.0, 1.19)     5\n",
      "(0.83, 0.83, 5.0)     4\n",
      "(0.53, 0.53, 5.0)     4\n",
      "(0.89, 0.89, 5.0)     4\n",
      "(0.58, 0.58, 5.0)     4\n",
      "(0.63, 0.63, 5.0)     4\n",
      "(0.95, 0.95, 5.0)     4\n",
      "(0.62, 0.62, 2.0)     4\n",
      "(0.62, 0.62, 5.0)     4\n",
      "(1.41, 1.5, 1.41)     4\n",
      "(0.57, 0.57, 5.0)     3\n",
      "(0.59, 0.59, 5.0)     3\n",
      "(0.67, 0.67, 2.0)     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top image spacings (val):\n",
      "spacing_r\n",
      "(0.78, 0.78, 5.0)    14\n",
      "(0.69, 0.69, 3.0)     8\n",
      "(0.62, 0.62, 5.0)     5\n",
      "(0.66, 0.66, 2.0)     4\n",
      "(0.51, 0.51, 5.0)     4\n",
      "(1.41, 1.5, 1.41)     4\n",
      "(1.19, 1.19, 3.0)     4\n",
      "(0.65, 0.65, 5.0)     3\n",
      "(0.58, 0.58, 5.0)     3\n",
      "(0.77, 0.77, 2.0)     3\n",
      "(0.59, 0.59, 2.0)     3\n",
      "(0.69, 0.69, 2.0)     3\n",
      "(1.19, 3.0, 1.19)     3\n",
      "(0.64, 0.64, 2.0)     3\n",
      "(0.48, 0.48, 5.0)     3\n",
      "(0.77, 0.77, 5.0)     2\n",
      "(0.7, 0.7, 2.0)       2\n",
      "(0.65, 0.65, 2.0)     2\n",
      "(0.61, 0.61, 2.0)     2\n",
      "(0.53, 0.53, 5.0)     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — Optional: distribution of spacings (train/val)\n",
    "def parse_tuple_str(s):\n",
    "    if not isinstance(s, str) or not s.startswith(\"(\"):\n",
    "        return None\n",
    "    return tuple(float(x.strip()) for x in s.strip(\"()\").split(\",\"))\n",
    "\n",
    "def spacing_table(split: str):\n",
    "    sub = df[df[\"split\"] == split].copy()\n",
    "    sub[\"spacing\"] = sub[\"img_spacing\"].apply(parse_tuple_str)\n",
    "    sub = sub[sub[\"spacing\"].notna()]\n",
    "    # round spacings to 2 decimals for grouping\n",
    "    sub[\"spacing_r\"] = sub[\"spacing\"].apply(lambda t: tuple(round(x,2) for x in t))\n",
    "    return sub[\"spacing_r\"].value_counts().head(20)\n",
    "\n",
    "print(\"Top image spacings (train):\")\n",
    "print(spacing_table(\"train\"))\n",
    "print(\"\\nTop image spacings (val):\")\n",
    "print(spacing_table(\"val\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b36573",
   "metadata": {},
   "source": [
    "## What to paste back into chat\n",
    "\n",
    "After running this notebook, paste:\n",
    "- counts of **missing labels**, **shape mismatches**, and **unexpected label ranges**\n",
    "- (if any) 2–3 example case IDs with issues\n",
    "\n",
    "Then we can proceed to:\n",
    "- nnU-Net dataset preparation (`DatasetXXX_AMOS22`)\n",
    "- baseline training commands\n",
    "- unifying evaluation + report generation plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d94fbb-1b3d-46b8-9299-5f5fcc793c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- Configure paths/arguments ----\n",
    "script_path = Path(\"baseline_nnunet\") / \"prepare_dataset.py\"\n",
    "amos_root = Path(r\"C:\\Users\\hyeon\\Documents\\miniconda_medimg_env\\data\\amos22\")\n",
    "\n",
    "# Ensure NNUNet_raw exists in this kernel's environment (as set earlier)\n",
    "nnunet_raw = os.environ.get(\"NNUNet_raw\")\n",
    "if not nnunet_raw:\n",
    "    raise EnvironmentError(\"NNUNet_raw is not set in os.environ. Please set it earlier in the notebook.\")\n",
    "\n",
    "# Optional sanity checks (helpful in research workflows)\n",
    "assert script_path.exists(), f\"Script not found: {script_path.resolve()}\"\n",
    "assert amos_root.exists(), f\"AMOS root not found: {amos_root}\"\n",
    "assert Path(nnunet_raw).exists(), f\"NNUNet_raw path does not exist: {nnunet_raw}\"\n",
    "\n",
    "# ---- Build the command ----\n",
    "cmd = [\n",
    "    sys.executable,               # Use the same Python as the notebook kernel\n",
    "    str(script_path),\n",
    "    \"--amos_root\", str(amos_root),\n",
    "    \"--nnunet_raw\", nnunet_raw,\n",
    "    \"--dataset_id\", \"701\",\n",
    "    \"--dataset_name\", \"AMOS22\",\n",
    "]\n",
    "\n",
    "# ---- Run the command ----\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "# ---- Show output / error ----\n",
    "print(\"STDOUT:\\n\", result.stdout)\n",
    "if result.returncode != 0:\n",
    "    print(\"STDERR:\\n\", result.stderr)\n",
    "    raise RuntimeError(f\"Command failed with return code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5898fe-6618-4016-8919-25a110dabc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for var in [\"NNUNet_raw\", \"NNUNet_preprocessed\", \"NNUNet_results\"]:\n",
    "    assert Path(os.environ[var]).exists(), f\"{var} path does not exist\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (medimg)",
   "language": "python",
   "name": "medimg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
